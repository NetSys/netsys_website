- title: Zed - Leveraging Data Types to Process Heterogeneous and Evolving Data
  is_ongoing: true
  stage: ongoing
  stage_order: 2
  edge_project: zed
  participants: "Contact author: Amy Ousterhout, Silvery Fu"
  desc: >
    Processing heterogeneous and evolving data is challenging with today’s data frameworks. In the Zed project, we re-architect data processing from the ground up to handle data with heterogeneous and evolving schemas by design. We argue that the key to doing so is to make data types first-class members of our data-processing systems, particularly of our data models and query languages.
  links:
    - {
        name: Source Code,
        url: "https://github.com/aousterh/data_model",
        type: code,
        featured: false
    }

- title: dSpace
  is_ongoing: true
  stage: ongoing
  stage_order: 2
  edge_project: dspace
  participants: "Silvery Fu, Sylvia Ratnasamy"
  desc: >
    While there has been explosive growth in the diversity and availability of IoT devices, 
    systems support for the same has lagged far behind. As a result, existing IoT applications tend 
    to be tedious to implement and inflexible to operate. We propose dSpace, an open and modular 
    programming framework that aims to simplify both the development and operation of IoT applications. 
    dSpace provides two key building blocks - digivices that implement device control and actuation and 
    digilakes that process IoT data to generate events and insights — together with novel abstractions for 
    composing these building blocks into higher-level abstractions. 


- title: Vertex
  is_ongoing: true
  stage: ongoing
  stage_order: 2
  edge_project: vertex
  participants: "Lloyd Brown, Scott Shenker, Aurojit Panda, Amy Outerhout, Brian Kim, Michael Perry"
  desc: >
    The goal of edge computing is to make nearby computing resources available to a rich set of applications. However, current offerings provide incomplete interfaces that limit applications, and disparate interfaces that prevent applications from using edges from other providers. To fix this we propose Vertex, a standard edge computing interface to enable provider-agnostic edge computing with a fuller set of abstractions.

- title: Programmable RDMA
  is_ongoing: true
  stage: new
  stage_order: 2
  edge_project: rmc
  participants: "Contact author: Emmanuel Amaro"
  desc: >
    We propose extensions to RDMA called Remote Memory Calls (RMCs) that allows applications to 
    install a customized set of 1-sided RDMA operations. We are exploring how can RMCs be implemented 
    on the forthcoming generation of SmartNICs, and we will compare its performance to pure 1-sided and 2-sided 
    RDMA operations.
  feature_excerpt: >
    We propose extensions to RDMA called Remote Memory Calls (RMCs) that allows applications to 
    install a customized set of 1-sided RDMA operations. We are exploring how can RMCs be implemented 
    on the forthcoming generation of SmartNICs, and we will compare its performance to pure 1-sided and 2-sided 
    RDMA operations.

- title: CESSNA
  is_ongoing: true
  stage: ongoing
  stage_order: 3
  edge_project: cessna
  participants: Aisha Mushtaq, Yotam Harchol, Vivian Fang, Murphy McCauley, Aurojit Panda, Scott Shenker
  desc: >
    The introduction of computational resources at the network edge allows application designers 
    to offload computation from clients and/or servers, thereby reducing response latency and 
    backbone bandwidth. More fundamentally, edge-computing moves applications from a client-server 
    model to a client-edge-server model. While this is an attractive paradigm for many use cases, 
    it raises the question of how to design client-edge-server systems so they can tolerate edge 
    failures and client mobility. This is particularly challenging when edge processing is strongly 
    stateful. In this work we propose a design for meeting this challenge called the Client-Edge-Server 
    for Stateful Network Applications (CESSNA).
  feature_excerpt: >
    The introduction of computational resources at the network edge allows application designers 
    to offload computation from clients and/or servers. We propose a design called the Client-Edge-Server 
    for Stateful Network Applications (CESSNA) for client-edge-server systems so they can tolerate 
    edge failures and client mobility.
  links:
    - {
        name: Paper,
        url: "https://dl.acm.org/doi/10.1145/3229556.3229558",
        type: paper,
        featured: false
    }

- title: CellBricks
  is_ongoing: true
  stage: ongoing
  stage_order: 2
  edge_project: mutcell
  participants: "Zhihong Luo, Silvery Fu, Mark Theis, Shaddi Hasan, Sylvia Ratnasamy, Scott Shenker"
  desc: >
    Markets in which competition thrives are good for both consumers and innovation but, 
    unfortunately, competition is not thriving in the increasingly important cellular market.
    We propose CellBricks, a novel cellular architecture that lowers the barrier to entry for
    new operators by enabling users to consume access on-demand from any available cellular 
    operator — small or large, trusted or untrusted. CellBricks achieves this by moving support 
    for mobility and user management (authentication and billing) out of the network and into end hosts. 
    These changes, we believe, bring valuable benefits beyond enabling competition: they lead to a cellular 
    infrastructure that is simpler and more efficient. We design, build, and evaluate CellBricks, 
    showing that its benefits come at little-to-no cost in performance compared to what's achieved 
    by current cellular infrastructure.
  feature_excerpt: >
    We propose CellBricks, a novel cellular architecture that lowers the barrier to entry for
    new operators by enabling users to consume access on-demand from any available cellular 
    operator — small or large, trusted or untrusted.

- title: Efficient Work Stealing
  is_ongoing: true
  stage: early
  stage_order: 1
  edge_project: workstealing
  participants: "Contact author: Amy Ousterhout"
  desc: >
    Datacenter servers must balance load across many (sometimes dozens) of cores. 
    Existing techniques such as work stealing perform well for long tasks, but can be inefficient for short tasks 
    that take only a couple of microseconds. At these timescales, cores may spend a significant fraction of their 
    time just looking for work, rather than actually doing useful work; this wastes CPU resources that could be 
    used by other applications on the same server. We are exploring techniques to perform load balancing more 
    efficiently, so that requests are handled faster and cores waste fewer cycles looking for work. 
  feature_excerpt: >
    Existing techniques such as work stealing perform well for long tasks, but can be inefficient for short tasks 
    that take only a couple of microseconds. We explore techniques to perform load balancing more efficiently, 
    so that requests are handled faster and cores waste fewer cycles looking for work. 

- title: Kappa
  url: "https://kappa.cs.berkeley.edu/"
  is_ongoing: true
  stage: finished
  stage_order: 4
  edge_project: kappa
  participants: Wen Zhang, Vivian Fang, Aurojit Panda, Scott Shenker
  desc: >
    Serverless computing (e.g., AWS Lambda) was initially designed for event-driven applications, 
    where each event handler is guaranteed to complete within a limited time duration. Kappa aims 
    to enable general purpose, parallel computation on serverless platforms. To do this, Kappa 
    provides a continuation-based checkpointing mechanism that allows long-running computations on 
    time-bounded lambda functions; and, a message-passing concurrency API for easily expressing 
    parallelism and exploiting the elasticity of serverless platforms.
  links:
    - {
        name: Source Code,
        url: "https://github.com/NetSys/kappa",
        type: code,
        featured: false
    }

- title: Automating GDPR
  is_ongoing: true
  stage: new
  stage_order: 2
  participants: Michael Alan Chang, Wen Zhang, Eric Sheng, Aurojit Panda, Scott Shenker
  desc: >
    Recent Data Privacy Acts like GDPR and CCPA necessitate well-defined data APIs between data 
    security/privacy personnel and application developers. However, poor data governance in Kubernetes 
    applications poses a major obstacle towards developing this API. Data tends to be disorganized, 
    decentralized, and redundant, and is stored under different names over different databases, views, 
    tables -- all of which are constantly being changed. Thus, tracking and controlling application-wide 
    data flow is currently impossible. We have developed a network control plane for data 
    that provides developer with a centralized interface to enforce policy around data. 
    Moreover, we have developed the theoretical foundations to formally guarantee that incoming 
    queries are compliant with the operator-specified policies.
  feature_excerpt: >
    We developed a network control plane for data that provides developer with a centralized interface to enforce policy around data. 
    We also built theoretical foundations to formally guarantee that incoming queries are compliant with the operator-specified policies.

- title: RCS
  is_ongoing: true
  stage: new
  stage_order: 2
  edge_project: rcs
  participants: Lloyd Brown, Arvind Krishnamurth (UW), Ganesh Ananthanarayanan (MSR), Ethan Katz Basset (Columbia), Sylvia Ratnasamy, Scott Shenker
  desc: >
    The conventional wisdom requires that all congestion control algorithms deployed on the public Internet be TCP-friendly. 
    If universally obeyed, this requirement would greatly constrain the future of such congestion control algorithms. 
    If partially ignored, as is increasingly likely, then there could be significant inequities in the bandwidth 
    received by different flows. To avoid this dilemma, we propose an alternative to the TCP-friendly paradigm 
    that can accommodate innovation, is consistent with the Internet’s current economic model, and is feasible 
    to deploy given current usage trends.
  feature_excerpt: >
    The conventional wisdom requires that all congestion control algorithms deployed on the public Internet be TCP-friendly.
    We propose an alternative to the TCP-friendly paradigm that can accommodate innovation, is consistent with the Internet’s 
    current economic model, and is feasible to deploy given current usage trends.

- title: Autotune
  is_ongoing: true
  stage: ongoing
  stage_order: 3
  edge_project: autotune
  participants: Michael Alan Chang, Will Wang, Aurojit Panda, Scott Shenker
  desc: >
    Most large web-scale applications are now built by composing collections (up to 100s or 1000s) of microservices. 
    Operators need to decide how many resources are allocated to each microservice, and these allocations can have a 
    large impact on application performance. Manually determining allocations that are both cost-efficient and 
    meet performance requirements is challenging, even for experienced operators. In this paper we present 
    Autotune, an end-to-end tool that automatically minimizes resource utilization while maintaining good application performance.

- title: Persimmon
  is_ongoing: true
  stage: finished
  stage_order: 4
  edge_project: persimmon
  participants: Wen Zhang, Scott Shenker, Irene Zhang
  desc: >
    Distributed in-memory storage systems are crucial for meeting the low latency
    requirements of modern datacenter services. However, they lose all state on
    failure, so recovery is expensive and data loss is always a risk.  The
    Persimmon system leverages persistent memory (PM) to convert existing in-memory
    storage systems into persistent, crash-consistent versions with low overhead
    and minimal code changes. Persimmon offers a simple Persistent State Machine
    abstraction for PM and implements persistence through operation logging on the
    critical path and a novel crash-consistent shadow execution technique for log
    digestion in the background.
  feature_excerpt: >
    Distributed in-memory storage systems lose all state on failure, so recovery is expensive and data loss is always a risk.
    The Persimmon system leverages persistent memory (PM) to convert existing in-memory storage systems into persistent, 
    crash-consistent versions with low overhead and minimal code changes. 

- title: CFM
  url: "https://github.com/clusterfarmem"
  is_ongoing: true
  stage: finished
  stage_order: 4
  edge_project: cfm
  participants: Emmanuel Amaro, Christopher Branner-Augmon, Zhihong Luo, Amy Ousterhout, Marcos K. Aguilera, Aurojit Panda, Sylvia Ratnasamy, Scott Shenker
  desc: >
    As memory requirements grow, and advances in memory technology slow, the availability of sufficient 
    main memory is increasingly the bottleneck in large compute clusters. One solution to this is memory 
    disaggregation, where jobs can remotely access memory on other servers, or far memory. This project 
    presents a faster swapping mechanism and a far memory-aware cluster scheduler that make it possible 
    to support far memory at rack scale. While far memory is not a panacea, for memory-intensive workloads, 
    CFM can provide performance improvements on the order of 10% or more even without changing the total 
    amount of memory available.
  links:
    - {
        name: "Paper",
        url: "https://dl.acm.org/doi/abs/10.1145/3342195.3387522",
        type: paper,
        featured: false
    }
    - {
        name: Source Code,
        url: "https://github.com/clusterfarmem",
        type: code,
        featured: false
    }

- title: Understanding the root causes and fixes of congestion collapse
  is_ongoing: true
  stage: new
  stage_order: 2
  participants: "Contact author: Aisha Mustaq"
  desc: >
    In many ways, our current approach to Internet congestion control arose from the need to deal with a 
    series of congestion collapses. While some of those innovations were explicitly intended to prevent 
    congestion collapse, others helped give TCP better congestion control more generally. In this paper 
    we try to identify the aspects of congestion control that are necessary and sufficient to prevent 
    congestion collapse. We argue that -- in the context of a basic congestion control framework that 
    includes such features as sliding window, reasonably accurate RTTs, and backing off retransmit timers 
    -- we need two and only two relatively straightforward conditions on retransmit timers to prevent 
    congestion collapse. Making it easy to tell if a congestion control algorithm is congestion-collapse 
    resistant will be important as congestion control turns away from the current paradigm and adopts rather 
    different approaches, as is starting to occur.

- title: A Public Option for the Core
  is_ongoing: true
  stage: finished
  stage_order: 4
  edge_project: poc
  participants: "Contact author: Scott Shenker"
  desc: >
    This project is focused not on the Internet architecture -- as defined by layering, 
    the narrow waist of IP, and other core design principles -- but on the Internet infrastructure, 
    as embodied in the technologies and organizations that provide Internet service. We consider 
    both the challenges and the opportunities that make this an auspicious time to revisit how we might 
    best structure the Internet’s infrastructure. Currently, the tasks of transit-between-domains and 
    last-mile-delivery are jointly handled by a set of ISPs who interconnect through BGP. Instead, we propose 
    cleanly separating these two tasks. For transit, we propose the creation of a ``public option’' for the 
    Internet’s core backbone. This public option core, which complements rather than replaces the backbones 
    used by large-scale ISPs, would (i) run an open market for backbone bandwidth so it could leverage 
    links offered by third-parties, and (ii) structure its terms-of-service to enforce network neutrality 
    so as to encourage competition and reduce the advantage of large incumbents.

- title: Tunnels as an Abstraction
  is_ongoing: true
  stage: new
  stage_order: 2
  edge_project: tunnels
  participants: "Contact author: Scott Shenker"
  desc: >
    Network APIs such as UNIX sockets, DPDK, and Netmap, assume that networks provide 
    only end-to-end connectivity. However, networks increasingly include smartNICs and 
    programmable switches that can implement both network and application functions. 
    Several recent works have shown the benefit of offloading application functionality 
    to the network, but using these approaches requires changing not just the applications, 
    but also network and system configuration. In this project we propose a network API that 
    rovides a uniform abstraction for offloads, aiming to simplify their use.

- title: Economics of Data Sharing
  is_ongoing: true
  stage: early
  stage_order: 1
  edge_project: data-sharing
  participants: "Contact author: Scott Shenker"
  desc: >
    There are many learning tasks — detecting bank fraud, predicting treatment effectiveness 
    -- that are done by separate entities, but where sharing the data would produce better 
    results. However, there are both privacy and incentive problems with sharing data. We 
    propose the use of learning brokers that receive data from various entities and perform 
    two valuable functions. First, they run the training algorithms over the data, and only 
    give the inference engines to others, not the raw data. Second, they share the data in 
    such a way that all entities have an incentive to share everything with the broker. This 
    work is in the very early stages.

- title: Theory of Network Neutrality
  is_ongoing: true
  stage: early
  stage_order: 1
  edge_project: net-neutral
  participants: "Contact author: Scott Shenker"
  desc: >
    There is a huge literature on network neutrality, which typically starts with our current economic arrangements 
    on the Internet and asks about the wisdom of certain limited measures (such as termination fees or prioritizing service). 
    This projects instead looks at the set of economic actors and asks which economic arrangements would lead to the 
    socially optimal outcome. This work is in the very early stages.

- title: OS for the Modern Age
  is_ongoing: true
  stage: early
  stage_order: 1
  edge_project: os-redesign
  participants: "Contact author: Murphy McCauley"
  desc: >
     This NetSys project attempts to rethink foundational aspects of operating system design for 
     servers in the modern age, confronting issues such as changing performance bottlenecks (e.g., due 
     to vast performance changes in underlying technologies like networks and storage), the central 
     importance of isolation (in the sense of performance, data, and metadata), and shifting workloads 
     (such as extremely short and varied edge workloads).

- title: Routing Resilience
  is_ongoing: true
  stage: ongoing
  stage_order: 3
  participants: "Contact author: Murphy McCauley"
  desc: >
    A project in this area attempts to deliver a routing resiliency mechanism that is easily 
    implementable, easily deployable, and easily manageable while offering packet delivery rates 
    that rival those of the most sophisticated resiliency mechanisms.
  feature_excerpt: >
    A project in this area attempts to deliver a routing resiliency mechanism that is easily implementable, 
    easily deployable, and easily manageable while offering packet delivery rates that rival those of 
    the most sophisticated resiliency mechanisms.

- title: Smarter Prefetching
  is_ongoing: true
  stage: early
  stage_order: 1
  edge_project: prefetch
  participants: "Contact author: Christopher Branner-Augmon"
  desc: >
    Many common algorithms are data oblivious, meaning that their memory access patterns are independent of their input 
    data (e.g., common matrix operations). Our goal in this project is to exploit the predictability of memory access 
    patterns in data oblivious algorithms in order to reduce their memory footprint, while limiting their performance 
    degradation. We do this by utilizing a smart memory prefetcher, which is able to use information garnered from one 
    execution to accurately prefetch on subsequent executions of an application. For data-oblivious applications, our 
    approach will allow us to achieve much better prefetching accuracy when compared to existing approaches.
  feature_excerpt: >
    We propose a smart memory prefetcher to exploit the predictability of memory access patterns in data oblivious algorithms to 
    reduce their memory footprint, while limiting their performance degradation. It can use information garnered from one 
    execution to accurately prefetch on subsequent executions of an application. 

- title: Edgy
  is_ongoing: true
  stage: ongoing
  stage_order: 3
  edge_project: edgy
  participants: John Westhoff, Aisha Mushtaq, Amir Shahatit, Yotam Harchol, Aurojit Panda, Scott Shenker
  desc: >
    In the last few years there has been increased interest in deploying application logic at the network edge.  
    However, in order to effectively use edge resources, applications must replicate state at edges. In current 
    applications the policy for when and where state should be replicated is embedded in the application, 
    however this policy depends not just on application logic but also on workloads and resource availability. 
    Workload and resource availability can vary significantly over an application's lifetime, and this can result 
    in poor performance when adopting edge computing. In this work we propose Edgy, a framework that decouples 
    replication logic from application logic, thus enabling applications to better respond to workload and 
    infrastructure changes.

- title: TimeCrypt
  is_ongoing: false
  edge_project: timecrypt
  participants: Lukas Burkhalter, Anwar Hithnawi, Alexander Viand, Hossein Shafagh, Sylvia Ratnasamy
  desc: >
    A growing number of devices and services collect detailed time series data that is stored in the cloud. 
    Protecting the confidentiality of this vast and continuously generated data is an acute need for many applications 
    in this space. At the same time, we must preserve the utility of this data by enabling authorized services to 
    securely and selectively access and run analytics. This paper presents TimeCrypt, a system that provides scalable 
    and real-time analytics over large volumes of encrypted time series data. TimeCrypt allows users to define expressive 
    data access and privacy policies and enforces it cryptographically via encryption. In TimeCrypt, data is encrypted 
    end-to-end, and authorized parties can only decrypt and verify queries within their authorized access scope. Our evaluation 
    of TimeCrypt shows that its memory overhead and performance are competitive and close to operating on data in the clear.
  links:
    - {
        name: "NSDI Paper",
        url: "https://www.usenix.org/system/files/nsdi20-paper-burkhalter.pdf",
        type: paper,
    }

- title: Enabling a Permanent Revolution in Internet Architecture
  is_ongoing: true 
  participants: James Murphy McCauley, Yotam Harchol, Aurojit Panda, Barath Raghavan, Scott Shenker
  desc: >
    The research community has developed a number of interesting proposals for new Internet architectures 
    (e.g., NDN and XIA), which sometimes leads to asking the high stakes question of which one of these 
    new proposals should succeed the current Internet architecture. This project, presented at SIGCOMM 2019 
    as "Enabling a Permanent Revolution in Internet Architecture", explored a vision for the future wherein 
    multiple Internet architectures can be deployed on and coexist on the same existing infrastructure. The 
    proposed design radically reduces the requirements for deploying a new architecture (i.e., it doesn't 
    require replacing every router in the world), and removes the requirement that a single architectural 
    design must meet everyone's needs.
  links:
    - {
        name: "SIGCOMM Paper",
        url: "https://dl.acm.org/doi/10.1145/3341302.3342075",
        type: paper,
        featured: false
    }

- title: Savanna
  is_ongoing: true
  stage: ongoing
  stage_order: 3
  edge_project: savanna
  participants: Lloyd Brown, Peter Gao, Ed Oakes, Wen Zhang, Aurojit Panda, Sylvia Ratnasamy, Scott Shenker
  desc: >
    Serverless computing is a relatively recent cloud computing paradigm that allows customers 
    to write lightweight, short-lived functions that are executed on resources provisioned and managed by 
    cloud providers. This architecture was originally designed to simplify stateless, event-driven applications 
    such as those designed to handle web requests, compress images, or generate thumbnails. However, 
    this paradigm has been increasingly adopted in other domains including data analytics, machine learning, 
    and sensor data processing. These domains, and other potential applications, could benefit from better 
    fault-tolerance, consistent concurrent file access, and improved I/O performance than are provided by 
    current serverless offerings. In this paper we propose Savanna, a system that implements these features 
    for serverless applications. Savanna requires applications to use a file API, but is otherwise transparent 
    to serverless applications.

- title: DepSched
  is_ongoing: false
  stage: finished
  stage_order: 4
  edge_project: depsched
  participants: Silvery Fu, Radhika Mittal, Lei Zhang, Sylvia Ratnasamy
  desc: >
    Container is becoming the canonical way of deploying compute tasks at the edge. Unfortunately, container startup latency and overhead remain high, 
    limiting responsiveness and of edge deployment. This latency comes mostly from fetching container dependencies including system libraries, tools, 
    configuration files, and data files. To address this, we propose that schedulers in container orchestrators take into account a task's dependencies. 
    Hence, in dependency scheduling, the scheduler tries to place a task at a node that has the maximum number of the task's dependencies 
    stored locally. We implement dependency scheduling within Kubernetes and evaluate it through extensive experiments and measurement-driven 
    simulations. We show that dependency scheduling improves task startup latency by 1.4-2.3x relative to current dependency-agnostic 
    scheduling for typical scenarios.
  links:
    - {
        name: "Paper",
        url: "https://www.usenix.org/system/files/hotedge20_paper_fu.pdf",
        type: paper,
        featured: false
    }
    - {
        name: "Source Code",
        url: "https://github.com/kubernetes/kubernetes/pull/68081",
        type: code,
        featured: false
    }
  
- title: Predicting System Performance
  is_ongoing: true
  stage: finished
  stage_order: 4
  edge_project: perfpredict
  participants: Silvery Fu, Saurabh Gupta, Radhika Mittal, Sylvia Ratnasamy
  desc: >
    The ability to predict system performance is key to enabling better system optimization and planning. 
    Given recent advances in Machine learning (ML), one might 
    ask whether ML is a natural fit for this task. We study whether and how ML 
    can be used to predict performance. Our findings reveal that the performance variability
    stemming from optimization or randomization techniques in many applications makes performance 
    prediction inherently difficult, i.e. in such cases, no ML technique can predict performance 
    with high enough accuracy. We show how eliminating the discovered sources of variability 
    greatly improves prediction accuracy. Since it is difficult to eliminate all possible sources of 
    system performance variability, we further discuss how ML models can be extended to cope with them
    by learning a distribution as opposed to point estimates.

- title: Network Evolution for DNNs
  is_ongoing: false
  participants:  Michael Alan Chang, Aurojit Panda, Scott Shenker
  desc: >
    Deep Neural Networks increasingly power applications like image search, voice recognition, autonomous vehicles, 
    spam detection, datacenter power management, etc. Many of these applications require DNNs to be periodically retrained, 
    thereby improving prediction quality. As a result improving DNN training time has a significant impact on application performance. 
    As a result DNN training is increasingly distributed across machines, and executed on GPUs, ASICs, or other specialized hardware. 
    In this paper we analyze how the network fabric impacts DNN training time in order to determine how the network fabric should 
    change to better accommodate these jobs. We rely on analytical models and trace driven simulation for our analysis and find 
    that changing the network fabric can significantly impact DNN training performance, but unlike traditional data parallel systems 
    the biggest improvements come from improving data distribution mechanisms rather than aggregation mechanisms.
  links:
    - {
        name: SysML Paper,
        url: "https://arxiv.org/abs/2004.10275",
        type: paper,
        featured: false
    }

- title: "Datacenter Congestion Control: Identifying what is essential and making it practical"
  is_ongoing: false
  participants: Aisha Mushtaq, Radhika Mittal, James Murphy McCauley, Mohammad Alizadeh, Sylvia Ratnasamy, Scott Shenker
  desc: >
    Recent years have seen a slew of papers on datacenter congestion control mechanisms. In this work, 
    we ask whether the bulk of this research is needed for the common case where congestion control involves 
    hosts responding to simple congestion signals from the network and the performance goal is reducing some 
    average measure of flow completion time. We raise this question because we find that, out of all the possible 
    variations one could make in congestion control algorithms, the most essential feature is the switch scheduling 
    algorithm. More specifically, we find that congestion control mechanisms that use Shortest-Remaining-Processing-Time 
    (SRPT) achieve superior performance as long as the rate-setting algorithm at the host is reasonable. We further 
    find that while SRPT’s performance is quite robust to host behaviors, the performance of schemes that use scheduling 
    algorithms like FIFO or Fair Queuing depend far more crucially on the rate-setting algorithm, and their performance 
    is typically worse than what can be achieved with SRPT. Given these findings, we then ask whether it is practical 
    to realize SRPT in switches without requiring custom hardware. We observe that approximate and deployable SRPT (ADS) 
    designs exist, which leverage the small number of priority queues supported in almost all commodity switches, and require 
    only software changes in the host and the switches. Our evaluations with one very simple ADS design shows that 
    it can achieve performance close to true SRPT and is significantly better than FIFO. Thus, the answer to our 
    basic question - whether the bulk of recent research on datacenter congestion control algorithms is needed for the common case - is no.
  links:
    - {
        name: SIGCOMM-CCR Paper,
        url: "https://ccronline.sigcomm.org/2019/ccr-july-2019/datacenter-congestion-control-identifying-what-is-essential-and-making-it-practical/",
        type: paper,
        featured: false
    }

- title: BESS
  is_ongoing: false
  participants: Sangjin Han, Keon Jang, Dongsu Han, Sylvia Ratnasamy
  desc: >
    Modern NICs implement various features in hardware, such as protocol
    offloading, multicore supports, traffic control, and self virtualization. This
    approach exposes several issues: protocol dependence, limited hardware resources,
    and incomplete/buggy/non-compliant implementation. Even worse, the slow
    evolution of hardware NICs due to increasingly overwhelming design
    complexity cannot keep up in time with the new protocols and rapidly
    changing network architectures. We introduce the SoftNIC architecture to
    fill the gap between hardware capabilities and user demands. Our current
    SoftNIC prototype implements sophisticated NIC features on a few dedicated
    processor cores, while assuming only streamlined functionalities in
    hardware. The preliminary evaluation results show that most NIC features can
    be implemented in software with minimum performance cost, while the
    flexibility of software provides further potential benefits.
  feature_excerpt: >
    BESS is a modular framework for software switches. BESS is neither
    pre-configured or hardcoded to perform particular functionality. Instead, you
    can configure your own packet processing datapath by composing small modules.
  links:
    - {
        name: "Paper",
        url: "http://www.eecs.berkeley.edu/Pubs/TechRpts/2015/EECS-2015-155.pdf",
        type: paper,
        featured: false
    }
    - {
        name: "Source Code",
        url: "https://github.com/NetSys/bess",
        type: code,
        featured: false
    }

- title: E2
  url: "/projects/e2.html"
  is_ongoing: false
  participants: Shoumik Palkar, Chang Lan, Sangjin Han, Keon Jang, Aurojit Panda,
    Melvin Walls, Christian Maciocco, Sylvia Ratnasamy, Joshua Reich,
    Luigi Rizzo, Scott Shenker
  desc: >
    By moving network appliance functionality from proprietary hardware to software,
    Network Function Virtualization promises to bring the advantages of cloud
    computing to network packet processing. However, the evolution of cloud
    computing (particularly for data analytics) has greatly benefited from
    application-independent methods for scaling and placement that achieve high
    efficiency while relieving programmers of these burdens. NFV has no such general
    management solutions. To this end, we present E2 -- a scalable and
    application-agnostic scheduling framework for packet processing.
  links:
    - {
        name: SOSP Paper,
        url: "https://people.eecs.berkeley.edu/~sylvia/cs268-2016/papers/e2.pdf",
        type: paper,
        featured: false
    }
    - {
        name: Slides,
        url: /static/slides/IEEE-NFV2015-final.pptx,
        type: slides
    }
    - {
        name: Source Code,
        url: "https://github.com/NetSys/e2",
        type: code,
    }

- title: NetBricks
  is_ongoing: false
  participants: Aurojit Panda, Sangjin Han, Keon Jang, Melvin Walls,
    Sylvia Ratnasamy, Scott Shenker
  desc: >
    The move from hardware middleboxes to software net-work functions, as
    advocated by NFV, has proven morechallenging than expected. Developing new NFs
    remains a tedious process, with developers frequently having to re-discover and
    reapply the same set of optimizations, while current techniques for safely
    running multiple NFs (using VMs or containers) incur high performance overheads.
    In this paper we describe NetBricks, a new NFV framework that aims to improve both
    the building and running of NFs. For building NFs we take inspiration from
    databases and modern data analytics frameworks (e.g.,Spark andMap Reduce) and
    build a framework with a small set of customizable network processing elements.
    To improve execution performance, NetBricks builds on safe languages and
    runtimes to provide isolation in software, rather than relying on hardware
    isolation. NetBricks provides memory isolation comparable to VMs, without the
    associated performance penalties. To provide efficient I/O, we introducea novel
    technique called zero-copy software isolation.
  feature_excerpt: >
    NetBricks is a safe and fast framework for rapid development of network
    functions for use in NFV written using Rust and DPDK. NetBricks aims to make it
    faster to develop new NFs, while also providing faster mechanisms for safely
    chaining NFs. 
  links:
    - {
        name: "OSDI Paper",
        url: "https://people.eecs.berkeley.edu/~apanda/assets/papers/osdi16.pdf",
        type: paper,
        featured: false
    }
    - {
        name: "Source Code",
        url: "https://github.com/netsys/NetBricks",
        type: code,
        featured: false
    }

- title: Quilt
  is_ongoing: false
  participants: Ethan J. Jackson, et. al
  desc: >
    Quilt aims to be the easiest way to deploy and network containers.

    Traditional container orchestrators have a procedural API focused narrowly on
    compute. The network, usually an afterthought, must be managed by a separate
    system with its own independent API. This leaves operators with a complex task:
    write a deployment script that configures everything necessary to get their
    application up and running.

    Quilt takes a different approach. It relies on a new domain specific language,
    Stitch, to specify distributed applications, independent of the specific
    infrastructure they run on. Given a stitch, Quilt can automatically deploy in a
    variety of environments: Amazon EC2, Microsoft Azure, and Google Compute Engine,
    with more coming soon. Furthermore it can do this with no setup -- just point
    Quilt at a stitch and it will take care of the rest: booting virtual machines,
    starting containers on those VMs, and ensuring they can communicate.

    Quilt is currently in alpha and under heavy development. Please try it out! We
    are eager for feedback!
  # feature_excerpt: >
    # Quilt aims to be the easiest way to deploy and network containers by relying
    # on a new domain specific language, Stitch, to specify distributed applications.
  links:
    - {
        name: "Source Code",
        url: "https://github.com/NetSys/quilt",
        type: code,
        featured: false
    }

- title: Recursively Cautious Congestion Control
  is_ongoing: false
  participants: Radhika Mittal, Justine Sherry, Sylvia Ratnasamy, Scott Shenker
  desc: >
    Any congestion control mechanism has two primary goals - to fill the pipe and to
    do no harm to other flows in the network. These two goals conflict with
    eachother – the former requires aggressiveness, whereas the latter requires
    caution. Traditional approaches use the same mechanism (the sending rate) to
    achieve these two conflicting goals. For example, TCP cautiously probes for
    bandwidth using slow-start, starting with a small initial window and then
    ramping up, in order to fill the pipe. As a result, it often takes flows several
    round-trip times to fully utilize the available bandwidth.  RC3 simply decouples
    these two goals by sending additional packets from the flow using several layers
    of low priority service, to fill the pipe, while TCP runs as usual at higher
    priority. It can therefore, quickly take advantage of available capacity from
    the very first RTT to achieve near-optimal throughputs and smaller flow
    completion times while preserving TCP-friendliness and fairness. In common
    wide-area scenarios, RC3 results in a 40% reduction in average flow completion
    times, with strongest improvements – more than 70% reduction in flow completion
    time – seen in medium to large sized (100KB - 3MB) flows.
  links:
    - {
        name: "HotNets Paper",
        url: "http://conferences.sigcomm.org/hotnets/2013/papers/hotnets-final19.pdf",
        type: paper,
    }

- title: CANDID - Classifying Assets in Networks by Determining Importance and Dependencies
  is_ongoing: false
  participants: Scott Marshall, Sylvia Ratnasamy, and Vern Paxson
  desc: >
    CANDID is a passive NetFlow-based network traffic analysis platform targeted at
    inferring relationships and dependencies among services running on hosts in
    enterprise networks. These networks present challenges of great scale,
    complexity, and nonstop dynamism, which hinder the ability for network
    administrators to maintain insight into the complex relationships that exist in
    these networks. Consequently, administrators do not always know how best to
    proceed if a network failure occurs. CANDID strives to empower administrators by
    illuminating these relationships, such that they will be prepared to remedy
    complex service failures. The solutions we present take the first steps towards
    understanding these complex in-network relationships, with a special focus on
    inferring one class of dependencies and detecting load balanced services. The
    current focal point of our work is two radically different, yet complementary,
    strategies for inferring the presence of load balancing for pairs of systems. We
    leverage a case study using real NetFlow data from the network located at
    Lawrence Berkeley National Lab to validate our strategies. Promising results
    indicate this problem space is rich with unanswered research questions and is
    worthy of further exploration.
  links:
    - {
        name: "M.S. Thesis",
        url: "http://www.eecs.berkeley.edu/Pubs/TechRpts/2013/EECS-2013-64.html",
        type: paper,
    }

- title: STS
  is_ongoing: false
  participants: Colin Scott, Andreas Wundsam, Barath Raghavan, Aurojit Panda,
    Zhi Liu, Sam Whitlock, Ahmed El-Hassany, Andrew Or, Jefferson Lai, Eugene Huang,
    Kyriakos Zarifis, and Scott Shenker
  desc: >
    Software bugs are inevitable in software-defined networking control software,
    and troubleshooting is a tedious, time-consuming task. In this paper we discuss
    how to improve control software troubleshooting by presenting a technique for
    automatically identifying a minimal sequence of inputs responsible for
    triggering a given bug, without making assumptions about the language or
    instrumentation of the software under test. We apply our technique to five open
    source SDN control platforms—Floodlight, NOX, POX, Pyretic, ONOS—and illustrate
    how the minimal causal sequences our system found aided the troubleshooting
    process.
  links:
    - {
        name: "Paper Draft",
        url: "http://www.eecs.berkeley.edu/~rcs/research/sts.pdf",
        type: paper,
    }
    - {
        name: "Stanford CTO Summit Slides",
        url: "http://www.eecs.berkeley.edu/~rcs/research/troubleshooting_with_mcses.pptx",
        type: slides,
    }
    - {
        name: "Source Code",
        url: "http://ucb-sts.github.com/sts/",
        type: code,
    }

- title: Sparrow
  is_ongoing: false
  participants: Kay Outerhout, Patrick Wendall, Matei Zaharia, Ion Stoica
  desc: >
    Sparrow is a high throughput, low latency distributed cluster scheduler. Sparrow
    is designed for applications that require frequent research allocations due to
    launching very short jobs (e.g., jobs composed of 100ms tasks). To ensure that
    scheduling does not become a bottleneck, Sparrow distributes scheduling over
    several loosely coordianted machines. Each scheduler uses a constant-time
    scheduling algorithm based on on-demand feedback acquired by probing slave
    machines. Sparrow can perform task scheduling in milliseconds, two orders of
    magnitude faster than existing approaches.
  links:
    - {
        name: "Tech Report",
        url: "http://www.pwendell.com/docs/sparrow-submission.pdf",
        type: paper,
    }
    - {
        name: "Source Code",
        url: "https://github.com/radlab/sparrow",
        type: code,
    }

- title: MegaPipe
  is_ongoing: false
  participants: Sangjin Han, Scott Marshall, Byung-Gon Chun, and Sylvia Ratnasamy
  desc: >
    BSD Sockets has been a de facto standard API for network programming. While it
    provides a simple and portable way to perform network I/O, it shows suboptimal
    performance for “message-oriented” network workloads, where connections are
    short or messages are small. This problem is exacerbated by its poor scalability
    on multi-core processors. In this work, we explore the benefits of a clean-slate
    design of network APIs aimed at achieving both high performance and ease of
    programming. We present MegaPipe, a new API for efficient, scalable network I/O,
    and evaluate its efficiency and effectiveness with a proof-of-concept
    implementation.
  links:
    - {
        name: "OSDI Paper",
        url: "http://www.eecs.berkeley.edu/~sangjin/static/pub/osdi2012_megapipe.pdf",
        type: paper,
    }

- title: DDC
  is_ongoing: false
  participants: Junda Liu, Aurojit Panda, Ankit Singla, P. Brighten Godfrey, Michael Schapira, Scott Shenker
  desc: >
    Ensuring basic connectivity in the network is generally handled by the control
    plane. However control plane convergence times are several orders of magnitude
    larger than the rate at which switches forward packets, which means that after a
    failure the network might be disrupted for a while, even though the network is
    not partitioned. Traditionally, networks have handled this problem by
    precomputing a set of backup paths, over which traffic can be redirected in the
    case of link failures. The most widely deployed example of such a mechanism is
    MPLS FRR, however MPLS fast-reroute can only handle a limited number of link
    failures. A natural question that arises is whether one could design a static
    mechanism, capable of dealing with any arbitrary set of link failures? We have
    shown that a static mechanism cannot handle an arbitrary set of failures.

    Given this result, one must rely on a dynamic mechanism to guarantee ideal
    connectivity (i.e. packets are delivered as long as a network is connected, and
    barring congestion related drops). Previous work in this area, has resulted in
    algorithms that both require unbounded space in packet headers, and NP-complete
    computations to provide this guarantee. We propose a new algorithm, Data Driven
    Connectivity, which guarantees ideal connectivity, uses a single bit in the
    packet header, and can be carried out at line rate. 
  links:
    - {
        name: "NSDI Paper",
        url: "http://eecs.berkeley.edu/~apanda/paper/nsdi13.pdf",
        type: paper,
    }

- title: APLOMB
  is_ongoing: false
  participants: Justine Sherry, Shaddi Hasan, Colin Scott, Arvind Krishnamurthy, Sylvia Ratnasamy, Vyas Sekar
  desc: >
    Middleboxes – such as firewalls, proxies, and WAN optimizers – have become
    almost ubiquitous in modern enterprises. In a survey of 57 enterprise network
    administrators, we found that these devices, while popular, are costly, error
    prone, and hard to manage. To ease these challenges, we developed APLOMB: a
    service for outsourcing middleboxes to the cloud entirely. With APLOMB,
    enterprise clients tunnel all of their Internet traffic to and from a cloud
    provider; the traffic undergoes middlebox processing at the cloud before being
    forwarded out to the Internet at large. Our implementation is built from open
    source components including Vyatta and OpenVPN; we hope to have a
    publicly-available service soon. 
  links:
    - {
        name: "SIGCOMM Paper",
        url: "http://homes.cs.washington.edu/~arvind/papers/mbox-cloud.pdf",
        type: paper,
    }

- title: NetCalls
  is_ongoing: false
  participants: Justine Sherry, Shaddi Hasan, Colin Scott, Arvind Krishnamurthy, Sylvia Ratnasamy, Vyas Sekar
  desc: >
    Modern networks deploy middleboxes to support numerous advanced processing
    capabilities such as firewalling, traffic compression, and caching. Despite the
    widespread deployment of these features, they are nevertheless invisible to the
    end hosts using the network. We designed ‘network calls’ (netcalls) to allow end
    hosts to make function calls to the network processing their traffic, allowing
    the end hosts to invoke and configure the numerous advanced features provided by
    the networks their traffic traverses. For example, we built a web server that,
    upon detecting it is under attack using application-layer knowledge, adds
    additional filters to the firewalls in its network. A key challenge to netcalls
    is that we want to allow advanced configuration to end hosts not only in their
    local network, but in any network their traffic traverses. Thus, the netcalls
    architecture lies primarily in two components: an intra-domain protocol for end
    hosts to invoke function calls with their network provider, and an inter-domain
    protocol, by which providers invoke features in each others networks on behalf
    of their clients. Source code forthcoming.
  links:
    - {
        name: "Tech Report",
        url: "http://www.eecs.berkeley.edu/Pubs/TechRpts/2012/EECS-2012-240.html",
        type: paper,
    }

- title: POX
  is_ongoing: false
  participants:
  desc: >
    POX is a Python framework for writing network control software. At its most
    minimal, it is an OpenFlow controller. It targets research and education, and
    favors ease of use over most other concerns.
  links:
    - {
        name: "Website",
        url: "http://www.noxrepo.org/",
        type: misc,
    }
    - {
        name: "Source Code",
        url: "https://github.com/noxrepo/pox",
        type: code,
    }

